---
title: "Correct Barbell Use"
author: "Mark Barkell"
date: "November 26, 2017"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Summary

This report describes data collected by a fitness tracker.  The *classe* variable of the data indicates something about whether a person is doing a correct barbell use.

## Data Meaning

The *classe* variable has five distinct enumerations:

> Six young health participants were asked to perform one set of 10 repetitions of the Unilateral Dumbbell Biceps Curl in five different fashions: exactly according to the specification (Class A), throwing the elbows to the front (Class B), lifting the dumbbell only halfway (Class C), lowering the dumbbell only halfway (Class D) and throwing the hips to the front (Class E).
-- The data description web page.

## Downloading of the data

```{r download}
trainingFileName <- "pml-training.csv"
testingFileName <- "pml-testing.csv"
trainingUri <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
testingUri <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"
if (!file.exists(trainingFileName)) {
  download.file(trainingUri, trainingFileName)
}
if (!file.exists(testingFileName)) {
  download.file(testingUri, testingFileName)
}
testing <- read.csv(testingFileName)
training <- read.csv(trainingFileName)

```



## Data Modeling

The exploration of the data has been done with the code seen here.  The path to reach the current state of the code was to look at which possible predictors did not have N/A's, which predictors were not factors, and which predictors did not identify the user or a particular time encoding.

The determination of which predictors to use was done manually by visual inspection and by looking at the results of r statements such as

```{r understandingcolumns}
#lapply(colnames(training), function(x) { if (0 == sum(is.na(training[,x]))) { x }})
```


The excludeIndecies R function is used to say which columns could be used as predictors.  

Having done sums to determine whether the data was balenced I noticed many more "A" instances of **classe** than the other values.  So, I used upSample to make the impressions seem of equal factor level occurrences.

The reason I commented out roll\_belt, pitch\_belt, and yaw\_belt is their high correlation with many other predictors.  Including them as predictors degraded predictions in many of the development runs I did.

I performed many different models and am demostrating two of them in this decisionTree code.   After not getting enough correct with fda, mda, bagFDA, bagFDAGcv, as the types for the m model variable, I saw that treebag worked very well.  On the prediction test 18 of 20 are correct when predicting off of just tree bag.  The other model which is shown with pt and p variables are results, has 16 of 20 correct.  Both of these would have been sufficient to pass the Coursera JHU Practical Machine Learning Prediction Assignment.   The most of the code seen here is to do the blended glm/treebag model which yielded 16 of 20 correct.  (The reason I know how many correct there are on both is that I learned by having so many failing models what the real answers were.)

The values of p and p2 are not printed in order to not show passing anwsers to the assignment on the Open Web.   The modeling in this file takes over 5.5 GB of RAM to Run using Microsoft R-Open 3.4.0.  So, if anyone attmepts to run this, please note, it will fail on most home computers.

Throughout the assignment I did not graph the data.


```{r decisionTree}
set.seed(0x750ed0e7) # Used GNU/Linux command openssl rand -hex 4
library(caret)
training <- upSample(training, training$classe)
training <- training[,-which(colnames(training) %in% c("Class"))]
classeIndex <- which(colnames(training) == "classe")
notToIncludeIndecies <- which(colnames(training) %in% c("raw_timestamp_part_1", "raw_timestamp_part_2", "classe"))
excludeIndecies <- function(i) {
  if (i %in% notToIncludeIndecies)
  {
    
  }
  else if (0 != sum(is.na(training[,i])))
  {
    
  }
  else if (class(training[,i]) != "factor")
  {
    if (colnames(training)[i] 
        %in% 
        c(
#          "roll_belt",
#          "pitch_belt",
#          "yaw_belt",
          "gyros_arm_x", 
          "gyros_arm_y", 
          "gyros_arm_z",
          "accel_arm_x",
          "accel_arm_y",
          "accel_arm_z",
          "skewness_yaw_arm",
          "skewness_pitch_arm",
          "skewness_roll_arm",
          "pitch_dumbbell",
          "yaw_dumbbell",
          "roll_dumbbell",
          "roll_forearm",
          "yaw_forearm",
          "accel_belt_y",
          "accel_belt_x",
          "accel_belt_z",
          "accel_forearm_y",
          "accel_forearm_z",
          "accel_forearm_x",
          "gyros_forearm_y",
          "gyros_forearm_x",
          "gyros_forearm_z",
          "gyros_belt_x",
          "gyros_belt_y",
          "gyros_belt_z",
          "magnet_forearm_x",
         "magnet_forearm_z",
          "magnet_forearm_y",
          "magnet_belt_x",
          "magnet_belt_y",
          "magnet_belt_z",
          "gyros_arm_x",
          "gyros_arm_y",
          "gyros_arm_z",
          "accel_arm_x",
          "accel_arm_y",
          "accel_arm_z",
          "magnet_arm_y",
          "magnet_arm_z",
          "magnet_arm_x",
      ""
          ))
    {
      i
    }
  }
  else if (class(training[,i]) == "user_name")
  {
    
  }
  else if (class(training[,i]) == "factor" 
           && length(levels(training[,i])) < 53)
  {
      
  }
}
ctrl <- caret::trainControl(preProcOptions = list(thresh = .95))
nonNAIndeciesAndDoablePredictors <-  lapply(1:length(colnames(training)), excludeIndecies)
nonNAIndeciesAndDoablePredictors <- unlist(nonNAIndeciesAndDoablePredictors)


mIsA <- caret::train(y = as.factor(training[,classeIndex] == "A"), x = training[,nonNAIndeciesAndDoablePredictors], method="glm",
                  trControl = ctrl,
                  preProcess = c("center", "scale"),
                  na.action = na.fail
                  )

mIsB <- caret::train(y = as.factor(training[,classeIndex] == "B"), x = training[,nonNAIndeciesAndDoablePredictors], method="glm",
                  trControl = ctrl,
                  preProcess = c("center", "scale"),
                  na.action = na.fail
                  )


mIsC <- caret::train(y = as.factor(training[,classeIndex] == "C"), x = training[,nonNAIndeciesAndDoablePredictors], method="glm",
                  trControl = ctrl,
                  preProcess = c("center", "scale"),
                  na.action = na.fail
                  )

mIsD <- caret::train(y = as.factor(training[,classeIndex] == "D"), x = training[,nonNAIndeciesAndDoablePredictors], method="glm",
                  trControl = ctrl,
                  preProcess = c("center", "scale"),
                  na.action = na.fail
                  )



mIsE <- caret::train(y = as.factor(training[,classeIndex] == "E"), x = training[,nonNAIndeciesAndDoablePredictors], method="glm",
                  trControl = ctrl,
                  preProcess = c("center", "scale"),
                  na.action = na.fail
                  )

mIsAB <- caret::train(y = as.factor(grepl("^[AB]$", as.character(training[,classeIndex]))), x = training[,nonNAIndeciesAndDoablePredictors], method="glm",
                      trControl = ctrl,
                      preProcess = c("center", "scale"),
                      na.action = na.fail
                      )

mIsAC <- caret::train(y = as.factor(grepl("^[AC]$", as.character(training[,classeIndex]))), x = training[,nonNAIndeciesAndDoablePredictors], method="glm",
                      trControl = ctrl,
                      preProcess = c("center", "scale"),
                      na.action = na.fail
                      )

mIsAD <- caret::train(y = as.factor(grepl("^[AD]$", as.character(training[,classeIndex]))), x = training[,nonNAIndeciesAndDoablePredictors], method="glm",
                      trControl = ctrl,
                      preProcess = c("center", "scale"),
                      na.action = na.fail
                      )

mIsAE <- caret::train(y = as.factor(grepl("^[AE]$", as.character(training[,classeIndex]))), x = training[,nonNAIndeciesAndDoablePredictors], method="glm",
                      trControl = ctrl,
                      preProcess = c("center", "scale"),
                      na.action = na.fail
                      )



mIsBC <- caret::train(y = as.factor(grepl("^[BC]$", as.character(training[,classeIndex]))), x = training[,nonNAIndeciesAndDoablePredictors], method="glm",
                      trControl = ctrl,
                      preProcess = c("center", "scale"),
                      na.action = na.fail
                      )

mIsBD <- caret::train(y = as.factor(grepl("^[BD]$", as.character(training[,classeIndex]))), x = training[,nonNAIndeciesAndDoablePredictors], method="glm",
                      trControl = ctrl,
                      preProcess = c("center", "scale"),
                      na.action = na.fail
                      )

mIsBE <- caret::train(y = as.factor(grepl("^[BE]$", as.character(training[,classeIndex]))), x = training[,nonNAIndeciesAndDoablePredictors], method="glm",
                      trControl = ctrl,
                      preProcess = c("center", "scale"),
                      na.action = na.fail
                      )


mIsCD <- caret::train(y = as.factor(grepl("^[CD]$", as.character(training[,classeIndex]))), x = training[,nonNAIndeciesAndDoablePredictors], method="glm",
                      trControl = ctrl,
                      preProcess = c("center", "scale"),
                      na.action = na.fail
                      )

mIsCE <- caret::train(y = as.factor(grepl("^[CE]$", as.character(training[,classeIndex]))), x = training[,nonNAIndeciesAndDoablePredictors], method="glm",
                      trControl = ctrl,
                      preProcess = c("center", "scale"),
                      na.action = na.fail
                      )

mIsDE <- caret::train(y = as.factor(grepl("^[DE]$", as.character(training[,classeIndex]))), x = training[,nonNAIndeciesAndDoablePredictors], method="glm",
                      trControl = ctrl,
                      preProcess = c("center", "scale"),
                      na.action = na.fail
                      )



putPredict <- function(data) {
  data$isA <- as.logical(predict(mIsA, data))
  data$isB <- as.logical(predict(mIsB, data))
  data$isC <- as.logical(predict(mIsC, data))
  data$isD <- as.logical(predict(mIsD, data))
  data$isE <- as.logical(predict(mIsE, data))
  data$isAB <- as.logical(predict(mIsAB, data))
  data$isAC <- as.logical(predict(mIsAC, data))
  data$isAD <- as.logical(predict(mIsAD, data))
  data$isAE <- as.logical(predict(mIsAE, data))
  data$isBC <- as.logical(predict(mIsBC, data))
  data$isBD <- as.logical(predict(mIsBD, data))
  data$isBE <- as.logical(predict(mIsBE, data))
  data$isCD <- as.logical(predict(mIsCD, data))
  data$isCE <- as.logical(predict(mIsCE, data))
  data$isDE <- as.logical(predict(mIsDE, data))
  data
}

training <- putPredict(training)

#append(nonNAIndeciesAndDoablePredictors, which(colnames(training) %in% c("isA", "isB", "isC", "isD", "isE", "isAB", "isAC", "isAD", "isAE", "isBC", "isBD", "isBE", "isCD", "isCE", "isDE")))

testing <- putPredict(testing)

m <- caret::train(
  y = training[,classeIndex], 
  x = training[,nonNAIndeciesAndDoablePredictors],
  method = "treebag",
  trControl = ctrl,
  preProcess = c("center", "scale", "pca")
                  )


customPredict <- function(model, data, allowFieldIndexes)
{
  s <- mapply(function(isA, isB, isC, isD, isE, isAB, isAC, isAD, isAE, isBC, isBD, isBE, isCD, isCE, isDE) {
    aSum = isAB + isAC + isAD + isAE
    bSum = isAB + isBC + isBD + isBE
    cSum = isAC + isBC + isCD + isCE
    dSum = isAD + isBD + isCD + isDE
    eSum = isAE + isBE + isCE + isDE
    as.character(if (isA && !isB && !isC && !isD && !isE) { "A" }
    else if (!isA && isB && !isC && !isD && !isE) { "B" }
    else if (!isA && !isB && isC &&  isD && !isE) { "C" }
    else if (!isA && !isB && !isC && isD && !isE) { "D" }
    else if (!isA && !isB && !isC && !isD && isE) { "E" }
    else if (aSum > max(bSum, cSum, dSum, eSum)) { "A" }
    else if (bSum > max(aSum, cSum, dSum, eSum)) { "B" }
    else if (cSum > max(aSum, bSum, dSum, eSum)) { "C" }
    else if (dSum > max(aSum, bSum, cSum, eSum)) { "D" }
    else if (eSum > max(aSum, bSum, cSum, dSum)) { "E"}
    else { "F" })
  }, data$isA, data$isB, data$isC, data$isD, data$isE, data$isAB, data$isAC, data$isAD, data$isAE, data$isBC, data$isBD, data$isBE, data$isCD, data$isCE, data$isDE)
  p <- predict(model, data[,allowFieldIndexes])
  
  s[which(s == "F")] <- as.character(p[which(s == "F")])
  s
}

pt <- customPredict(model = m, data = training, allowFieldIndexes = nonNAIndeciesAndDoablePredictors)
p <- customPredict(model = m, data = testing, allowFieldIndexes = nonNAIndeciesAndDoablePredictors)

pt2 <- predict(m, training[,nonNAIndeciesAndDoablePredictors])
p2 <- predict(m, testing[,nonNAIndeciesAndDoablePredictors])


```

```{r modelInfo}
m
```

## References

### The original source of the data as according the assignment http://groupware.les.inf.puc-rio.br/har

#### The following is the license that the data for the web page asserts:

> Important: you are free to use this dataset for any purpose. This dataset is licensed under the Creative Commons license (CC BY-SA). The CC BY-SA license means you can remix, tweak, and build upon this work even for commercial purposes, as long as you credit the authors of the original work and you license your new creations under the identical terms we are licensing to you. This license is often compared to "copyleft" free and open source software licenses. All new works based on this dataset will carry the same license, so any derivatives will also allow commercial use. 

#### The following is the citation text the data's web site requests:

> Ugulino, W.; Cardador, D.; Vega, K.; Velloso, E.; Milidiu, R.; Fuks, H. Wearable Computing: Accelerometers' Data Classification of Body Postures and Movements. Proceedings of 21st Brazilian Symposium on Artificial Intelligence. Advances in Artificial Intelligence - SBIA 2012. In: Lecture Notes in Computer Science. , pp. 52-61. Curitiba, PR: Springer Berlin / Heidelberg, 2012. ISBN 978-3-642-34458-9. DOI: 10.1007/978-3-642-34459-6_6. 

### The asssignment's web page: https://www.coursera.org/learn/practical-machine-learning/supplement/PvInj/course-project-instructions-read-first


### The List of Caret Models
https://topepo.github.io/caret/available-models.html

### Applied Predictive Modeling, (c) 2013 By Max Kuhn and Kjell Johnson
